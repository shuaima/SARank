\section{Introduction}
\label{sec-intro}


Over the past a few years, research and development has made significant progresses on big data analytics with the supports from both governments and industries all over the world, such as Spark\footnote{\small \url{https://spark.apache.org}}, IBM Watson\footnote{\small \url{https://www.ibm.com/watson}} and Google AlphaGo\footnote{\small \url{https://deepmind.com/research/alphago}}. A fundamental issue for big data analytics is the efficiency, and various advances towards attacking this issues have been achieved recently, from theory to algorithms to systems~\cite{FanGN13,Jordan15,ZahariaXWDADMRV16}. However, {\em if the optimal solution is unable to attain or not required or has a price to high to pay, it is reasonable to sacrifice optimality with a ``good'' feasible solution that can be computed efficiently}. Hence, various approximation techniques have been developed, and can in general be classified into three aspects: algorithms, SQL aggregate queries and multiple layers of the system stack.

\bi
\item[(1)] {\em Approximation algorithms} were formally defined in the 1970s~\cite{GareyGU72,Johnson74a}. An approximation algorithm is necessarily polynomial, and is evaluated by the worst case possible relative error over all possible instances of the  NP-hard optimization problem, under the widely believed $P\ne NP$ conjecture. This is relatively mature research field algorithm community, many approximation algorithm have been designed for optimization problems (see books~\cite{Dorit96,approx03,Ausiello99}).
\item[(2)] {\em Approximate query processing} supports a slightly constrained set of SQL-style declarative queries, and it specifically provides approximate results for standard SQL aggregate queries, \eg queries involving COUNT, AVG, SUM and PERCENTILE. Over the past two decades, approximate query processing has been successfully studied, among which sampling technique are heavily employed~\cite{ChaudhuriDK17,Mozafari17,Kraska17,GarofalakisG01}. Not only traditional DBMS systems, such as Oracle\footnote{\small \url{https://oracle-base.com/articles/12c/approximate-query} \url{-processing-12cr2}},  provide approximate functions to support approximate results, but also emerging new systems specially designed for approximate queries, such as BlinkDB\footnote{\small \url{http://blindb.org/}}, Verdict\footnote{\small \url{http://verdictdb.org/}}, Simba\footnote{\small \url{https://initialdlab.github.io/Simba/index.html}}, have been designed. However, as pointed out in~\cite{ChaudhuriDK17}, `` it seems impossible to have an AQP system that supports the richness of SQL with significant saving of work while providing an accuracy guarantee that is acceptable to a broad set of application workloads.''

\item[(3)] {\em Approximation computing} is a recent computation technique that returns a possibly inaccurate result rather than a guaranteed accurate result from a system point of view.  It involves with multiple layers of the system stack from software to hardware to systems (such as approximate circuits, approximate storage and loop perforation), and can be used for applications where an approximate result is sufficient for its purpose~\cite{AgrawalCGGNOPSS16,Mittal16b}. Recently, a workshop on approximate computing across the stack has been usefully held for research on hardware, programming languages and compiler support  for approximate computing  since 2014.  (see \eg 2016\footnote{\small \url{http://approximate.computer/wax2016/}}, 2017\footnote{\small  \url{http://approximate.computer/wax2017/}} and 2018\footnote{\small \url{http://approximate.computer/wax2018/}}). Besides the various task oriented quality metrics,  the quality-energy trade-off is also  concerned for approximate computing. For example, in k-means clustering algorithm, allowing only 5\% loss in classification accuracy can provide 50 times energy saving compared with the fully accurate classification~\cite{Mittal16b}
\ei

In this article, we present the idea of approximate computation for efficient and effective big data analytics: query approximation and data approximation, based on our recent research experiences~\cite{MaCHW12,ShuaiMaVLDB12,tods-MaCFHW14,LinMZWH17,MaHWLH17,MaFLWCH16,MaFLWCH17,HuAMH16,DuanAMHH16,DuanMAMH17,rankicde2018}.
Approximation algorithms ask for feasible solutions that are theoretically bounded with respect to optimal solutions from an algorithm design aspect.
Approximate query processing and approximation computing relax the need for accuracy guarantees for aggregate SQL queries and for multiple layers of the system stack, respectively. Similarly, our approximate computation is unnecessarily theoretically bounded with respect to optimal solutions, but from an algorithm design point of view. That is, we focus on approximate computation for big data analytics for a situation where an approximate result is sufficient for a purpose.

%Different from existing approximation techniques~\cite{CormenLRS01,approx03,FanH14}, the approximation computation that we are going to introduce is unnecessarily theoretically bounded with respect to optimal solutions, but asks for both efficiency and effectiveness in practice.




